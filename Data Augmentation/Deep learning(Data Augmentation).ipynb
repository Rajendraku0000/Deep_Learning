{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8340f0e8",
   "metadata": {},
   "source": [
    "# Data Augmentation in CNN  ==> \n",
    "\n",
    "Data augmentation in CNN (Convolutional Neural Network) is a technique used to artificially increase the size of a training dataset by applying various transformations and modifications to the existing images. It helps to reduce overfitting and improve the generalization capability of the model by providing more diverse and representative examples for training.\n",
    "\n",
    "In CNNs, data augmentation is particularly effective because the convolutional layers are able to learn and extract meaningful features from the transformed images. By applying different transformations, the model can learn to recognize objects and patterns in various orientations, sizes, and positions, making it more robust to different real-world scenarios.\n",
    "\n",
    "Here is a step-by-step explanation of how data augmentation works in CNN:\n",
    "\n",
    "(1). Image Transformation: Data augmentation involves applying a range of transformations to the training images. Some commonly used transformations include:\n",
    "\n",
    "(a). Rotation: Rotating the image by a certain angle, which helps the model learn to recognize objects from different viewpoints.\n",
    "    \n",
    "(b). Translation: Shifting the image horizontally or vertically, which helps the model become invariant to object position within the image.\n",
    "    \n",
    "(c). Scaling: Resizing the image to different dimensions, which enables the model to recognize objects of various sizes.\n",
    "    \n",
    "(d). Flipping: Mirroring the image horizontally or vertically, which helps the model learn symmetry and handle objects facing different directions.\n",
    "    \n",
    "(e). Shearing: Distorting the image by shifting one side of the image relative to the other, which helps the model handle perspective transformations.\n",
    "    \n",
    "(f). Zooming: Zooming in or out of the image, which helps the model learn to recognize objects at different scales.\n",
    "    \n",
    "(g). Application of Transformations: During training, each training image is randomly selected and modified using one or more of the transformations mentioned above. The parameters of the transformations, such as rotation angle or zoom factor, are typically randomly chosen within predefined ranges. This randomness adds further diversity to the training data and prevents the model from memorizing specific patterns.\n",
    "    \n",
    "\n",
    "(2). Data Augmentation Pipeline: The transformed images are fed into the CNN model for training. The augmented images are typically generated on-the-fly during the training process rather than pre-generating and saving them, which saves storage space and allows for a more efficient training process.\n",
    "    \n",
    "\n",
    "Training Process: The CNN model is trained using the augmented data. The increased diversity in the training data helps the model learn robust features that are invariant to various transformations, making it more capable of generalizing to unseen examples.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c21de3",
   "metadata": {},
   "source": [
    "# summary ==> \n",
    "By applying data augmentation, the effective size of the training dataset is increased, which can lead to better performance and reduced overfitting. Additionally, data augmentation can help address the problem of imbalanced datasets by generating additional samples for underrepresented classes, thus improving the model's ability to recognize those classes.\n",
    "\n",
    "It's important to note that data augmentation should be carefully chosen based on the characteristics of the specific dataset and the problem at hand. Some transformations may not be suitable for certain types of images or may introduce unrealistic variations. Therefore, domain knowledge and experimentation are necessary to determine the most appropriate augmentation techniques for a given task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0ca6f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "\n",
    "# # Define the CNN model architecture\n",
    "# model = keras.Sequential([\n",
    "#     layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "#     layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "#     layers.Flatten(),\n",
    "#     layers.Dense(128, activation='relu'),\n",
    "#     layers.Dense(10, activation='softmax')\n",
    "# ])\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss='categorical_crossentropy',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# # Create an instance of the ImageDataGenerator class with data augmentation\n",
    "# datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "#     rotation_range=20,  # Randomly rotate images by 20 degrees\n",
    "#     width_shift_range=0.1,  # Randomly shift images horizontally by 10% of the width\n",
    "#     height_shift_range=0.1,  # Randomly shift images vertically by 10% of the height\n",
    "#     zoom_range=0.2,  # Randomly zoom in or out of images by 20%\n",
    "#     horizontal_flip=True  # Randomly flip images horizontally\n",
    "# )\n",
    "\n",
    "# # Load and augment the training dataset\n",
    "# train_dataset = datagen.flow_from_directory(\n",
    "#     'train_data_directory',  # Path to the directory containing the training images\n",
    "#     target_size=(32, 32),  # Resizing the images to a specific size\n",
    "#     batch_size=32,  # Number of images to augment in each batch\n",
    "#     class_mode='categorical'  # Type of problem (e.g., categorical, binary)\n",
    "# )\n",
    "\n",
    "# # Load the validation dataset\n",
    "# validation_dataset = keras.preprocessing.image_dataset_from_directory(\n",
    "#     'validation_data_directory',  # Path to the directory containing the validation images\n",
    "#     image_size=(32, 32),  # Resizing the images to a specific size\n",
    "#     batch_size=32\n",
    "# )\n",
    "\n",
    "# # Train the model using augmented data\n",
    "# model.fit(train_dataset, validation_data=validation_dataset, epochs=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5e49b2",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aedd1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image \n",
    "from tensorflow.keras.preprocessing.image import load_img , img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d43ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "rotation_range = 40,\n",
    "width_shift_range = 0.2 , \n",
    "height_shift_range = 0.2 , \n",
    "shear_range = 0.2 ,\n",
    "zoom_range = 0.2 ,\n",
    "horizontal_flip = True , \n",
    "fill_mode = 'nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90bb815",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(\"C:\\\\Users\\\\saurabh\\\\Desktop\\\\img\\\\dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "446e2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04c99e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape((1,) + x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e63a739",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 \n",
    "for batch in datagen.flow(x , batch_size = 1 , save_to_dir = \"C:\\\\Users\\\\saurabh\\\\Desktop\\\\img\" , save_prefix = 'dog' , save_format = 'jpeg'):\n",
    "    i += 1 \n",
    "    if i >10 :\n",
    "        break \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f20a3a",
   "metadata": {},
   "source": [
    "# How i decide  in which scenerio and which value I have for Rotation , Translation , Scaling , Flipping , Shearning , Zooming . in data Augmentation . ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9c3b94",
   "metadata": {},
   "source": [
    "# When deciding which data augmentation techniques to apply to your dataset, it's important to consider the specific characteristics of your data and the goals of your task. Here are some considerations for different augmentation techniques:\n",
    "\n",
    "(1). Rotation: Rotation can be useful when the orientation of objects in your data is important. For example, in image classification tasks, rotating images can help improve the model's ability to generalize to different angles of the object. The degree of rotation can vary depending on the nature of your data and the expected range of orientations.\n",
    "    \n",
    "\n",
    "(2). Translation: Translation involves shifting the position of objects in your data. It can be helpful when the location of objects within the image is not critical to the task. Translation can simulate slight shifts in camera perspective or object position, adding robustness to your model's performance. The magnitude and direction of translation should be chosen based on the specific requirements of your dataset.\n",
    "    \n",
    "\n",
    "(3). Scaling: Scaling refers to resizing the objects in your data. It can be beneficial when the size of objects is variable and doesn't affect the task's outcome. For instance, in object detection tasks, scaling can simulate objects appearing at different distances from the camera. The scale factor should be chosen to cover a reasonable range of object sizes in your dataset.\n",
    "    \n",
    "\n",
    "(4). Flipping: Flipping involves mirroring the data horizontally or vertically. It can be applied when the orientation of objects doesn't affect the task. For example, in image classification tasks, flipping can help the model learn invariant features such as left-right symmetry. The decision to flip horizontally or vertically depends on the specific characteristics of your data.\n",
    "    \n",
    "\n",
    "(5). Shearing: Shearing is a transformation that tilts or slants objects in your data. It can be useful when the shape or inclination of objects is relevant to the task. For instance, in handwriting recognition, shearing can simulate variations in handwriting styles. The degree and direction of shearing should be selected based on the nature of your data.\n",
    "    \n",
    "\n",
    "(6). Zooming: Zooming involves magnifying or reducing the size of objects in your data. It can be applied when the level of detail or the scale of objects is important. Zooming can help the model learn to recognize objects at different scales. The zoom level should be chosen to cover a reasonable range of object sizes in your dataset.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b6eafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc82114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
